{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1 – Install Libraries**"
      ],
      "metadata": {
        "id": "4M9m5rYjJIRb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fry0wu81EbJl",
        "outputId": "72464443-e525-4873-ab85-4a1634e7af8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.12/dist-packages (3.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers torch PyPDF2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2 – Import Dependencies**"
      ],
      "metadata": {
        "id": "ZvOmPnW9JMfY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch, PyPDF2\n",
        "from IPython.display import HTML\n"
      ],
      "metadata": {
        "id": "i1he_g5bEeZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3 – Convert PDF → Text**"
      ],
      "metadata": {
        "id": "GmkFjgp2JRr8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pdf_to_text(pdf_path):\n",
        "    text = \"\"\n",
        "    with open(pdf_path, \"rb\") as file:\n",
        "        reader = PyPDF2.PdfReader(file)\n",
        "        for page in reader.pages:\n",
        "            text += page.extract_text() + \"\\n\"\n",
        "    return text\n",
        "\n",
        "pdf_file = \"/content/AI AI_FinanceInsight (1).pdf\"  # ← your uploaded file\n",
        "text_content = pdf_to_text(pdf_file)\n",
        "\n",
        "# Save to .txt\n",
        "with open(\"sample_financial_report.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(text_content)\n",
        "print(\"✅ PDF converted to text successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMqVuWNDEj9B",
        "outputId": "6d9aae1d-7a0d-4eb9-f57c-792752b4c0a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ PDF converted to text successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4 – Load FinBERT Model**"
      ],
      "metadata": {
        "id": "4Y-aPEMgJXcG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"yiyanghkust/finbert-tone\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"yiyanghkust/finbert-tone\")\n"
      ],
      "metadata": {
        "id": "H1hGuxhkEmR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Step 5 – Run Sentiment Analysis***"
      ],
      "metadata": {
        "id": "i7kS7Mw4JetS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [s.strip() for s in text_content.split('.') if s.strip()]\n",
        "labels = ['neutral', 'positive', 'negative']\n",
        "\n",
        "results = []\n",
        "for sentence in sentences:\n",
        "    inputs = tokenizer(sentence, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "    outputs = model(**inputs)\n",
        "    probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "    label_id = torch.argmax(probs, dim=1).item()\n",
        "    results.append((sentence, labels[label_id], float(probs[0][label_id])))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KreWdr3xEoOK",
        "outputId": "bcff373a-caf2-48b7-e4a6-2026384d8c57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 6 – Create Color-Coded HTML**"
      ],
      "metadata": {
        "id": "Qw02dcZKJmWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "html_output = \"<html><body><h2>FinBERT Sentiment Analysis</h2>\"\n",
        "for sentence, label, score in results:\n",
        "    color = \"green\" if label == \"positive\" else \"red\" if label == \"negative\" else \"gray\"\n",
        "    html_output += f\"<p style='color:{color}'>{sentence} → {label.upper()} ({score:.2f})</p>\"\n",
        "html_output += \"</body></html>\"\n",
        "\n",
        "with open(\"finbert_results.html\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(html_output)\n",
        "\n",
        "print(\"✅ HTML file created: finbert_results.html\")\n",
        "HTML(html_output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HblTtieeEq7R",
        "outputId": "63a2b92f-2b5a-42e5-eba3-7e1b74518c9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ HTML file created: finbert_results.html\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<html><body><h2>FinBERT Sentiment Analysis</h2><p style='color:gray'>Project Proposal: FinanceInsight Developing Named Entity Recognition (NER) Models for Financial Data Extraction Introduction Named Entity Recognition (NER) plays a crucial role in the financial industry, where large volumes of unstructured data (such as reports, articles, and filings) contain valuable information for analysis → NEUTRAL (1.00)</p><p style='color:gray'>This project proposes to develop NER models aimed at extracting critical financial data from such documents → NEUTRAL (1.00)</p><p style='color:gray'>The models will focus on identifying and extracting key financial entities such as company names, stock prices, revenue, market capitalizations, earnings, dates, and financial events → NEUTRAL (1.00)</p><p style='color:gray'>This tool will cater to financial analysts, investors, and data scientists who need to efficiently extract and analyze financial information from large text datasets → NEUTRAL (0.99)</p><p style='color:gray'>Methodology NER Models for Financial Data ●Data Preparation: ○Collect a large corpus of financial texts such as earnings reports, SEC filings, financial news, and analyst reports → NEUTRAL (1.00)</p><p style='color:gray'>○Preprocess the data with techniques such as tokenization, part-of-speech tagging, and normalization → NEUTRAL (1.00)</p><p style='color:gray'>○Use domain-specific cleaning methods to handle financial jargon, symbols, and abbreviations (e → NEUTRAL (1.00)</p><p style='color:gray'>g → NEUTRAL (0.98)</p><p style='color:gray'>, handling currency symbols like $, €, or financial terms like EBITDA, P/E ratio) → NEUTRAL (1.00)</p><p style='color:gray'>●Financial NER Model: ○Basic NER for Financial Entities: Implement a model capable of identifying core financial entities such as company names, stock tickers, financial metrics (e → NEUTRAL (1.00)</p><p style='color:gray'>g → NEUTRAL (0.98)</p><p style='color:gray'>, revenue, earnings, growth rate), and important dates (e → NEUTRAL (1.00)</p><p style='color:gray'>g → NEUTRAL (0.98)</p><p style='color:gray'>, earnings announcements, fiscal year-end) → NEUTRAL (1.00)</p><p style='color:gray'>○Advanced Entity Extraction: Develop an advanced model to detect specific financial elements like net income, cash flow, gross profit, debt-to-equity ratio, and market sentiment from textual data → NEUTRAL (1.00)</p><p style='color:gray'>Custom Financial Data Extraction ●User-Defined Entity Extraction: ○Design the system to allow users to specify financial metrics they wish to extract → NEUTRAL (1.00)</p><p style='color:gray'>For example, users might be interested in extracting specific entities such as stock price trends, market cap, revenue growth, or earnings per share (EPS) → NEUTRAL (1.00)</p><p style='color:gray'>○Incorporate support for extracting specific financial ratios (e → NEUTRAL (1.00)</p><p style='color:gray'>g → NEUTRAL (0.98)</p><p style='color:gray'>, P/E ratio, dividend yield, return on equity) based on user input → NEUTRAL (1.00)</p><p style='color:gray'>●Extraction of Financial Events: ○Implement a model to detect financial events, such as mergers and acquisitions, stock splits, IPO announcements, and earnings calls, providing users with the ability to focus on particular events within a timeframe → NEUTRAL (0.97)</p><p style='color:gray'>Financial Document Segmentation and Parsing ●Financial Report Segmentation: ○Segment financial documents (e → NEUTRAL (1.00)</p><p style='color:gray'>g → NEUTRAL (0.98)</p><p style='color:gray'>, annual reports or 10-K filings) into meaningful sections such as \"Management’s Discussion and Analysis\" (MD&A), financial statements, and risk \n",
              "factors for more accurate extraction of relevant financial data → NEUTRAL (1.00)</p><p style='color:gray'>●Parsing of Financial Tables: ○Develop methods to identify and extract financial data from structured and semi-structured tables, commonly found in financial reports, ensuring the proper extraction of balance sheet items, cash flow figures, and profit and loss statements → NEUTRAL (1.00)</p><p style='color:gray'>Evaluation of Models ●Precision, Recall, F1-Score for Financial Data: ○Evaluate the performance of the NER models using domain-specific metrics to ensure accurate extraction of financial entities → NEUTRAL (1.00)</p><p style='color:gray'>○Domain-Specific Benchmarks: Test the models on diverse financial datasets such as news articles, earnings calls, and SEC filings to assess generalization across different text types → NEUTRAL (1.00)</p><p style='color:gray'>●Error Analysis: ○Conduct an error analysis to understand misclassifications, particularly for complex financial terms (e → NEUTRAL (1.00)</p><p style='color:gray'>g → NEUTRAL (0.98)</p><p style='color:gray'>, identifying differences between net income and operating income) → NEUTRAL (1.00)</p><p style='color:green'>Tools and Techniques ●Transformer-Based Models: ○Utilize pre-trained language models like BERT, FinBERT, or GPT fine-tuned on financial data to enhance NER capabilities for domain-specific tasks → POSITIVE (1.00)</p><p style='color:gray'>●Integration with Financial Databases: ○Link extracted data with financial databases (e → NEUTRAL (1.00)</p><p style='color:gray'>g → NEUTRAL (0.98)</p><p style='color:gray'>, Yahoo Finance, Bloomberg) to verify the accuracy and completeness of the extracted information → NEUTRAL (1.00)</p><p style='color:gray'>Architecture Diagram\n",
              " \n",
              "\n",
              " Expected Deliverables ●A fully functional NER model designed to extract financial entities such as stock prices, revenue, market cap, earnings, and financial events from large-scale text datasets → NEUTRAL (1.00)</p><p style='color:gray'>●A user interface for specifying which financial metrics and entities to extract (e → NEUTRAL (1.00)</p><p style='color:gray'>g → NEUTRAL (0.98)</p><p style='color:gray'>, stock price trends, company valuations, earnings data) → NEUTRAL (1.00)</p><p style='color:gray'>●An evaluation report comparing the effectiveness of various models (e → NEUTRAL (1.00)</p><p style='color:gray'>g → NEUTRAL (0.98)</p><p style='color:gray'>, CRF, BERT, FinBERT) for financial data extraction tasks → NEUTRAL (1.00)</p><p style='color:gray'>●Documentation detailing the methodology, implementation, and key insights gained from the project, including performance on financial benchmarks and error analysis → NEUTRAL (1.00)</p><p style='color:gray'>●Integration with external financial APIs for data validation and cross-referencing → NEUTRAL (1.00)</p><p style='color:gray'>Week-wise module implementation and high-level requirements Milestone 1: Weeks 1-2 (Data Preparation) Data Collection: •Collect a large corpus of financial texts, including earnings reports, SEC filings, financial news, and analyst reports → NEUTRAL (1.00)</p><p style='color:gray'>•Ensure the dataset covers a wide range of financial entities and events → NEUTRAL (1.00)</p><p style='color:gray'>Data Preprocessing: •Preprocess the data using techniques such as tokenization, part-of-speech tagging, and normalization → NEUTRAL (1.00)</p><p style='color:gray'>•Implement domain-specific cleaning methods to handle financial jargon, symbols, and abbreviations (e → NEUTRAL (1.00)</p><p style='color:gray'>g → NEUTRAL (0.98)</p><p style='color:gray'>, handling currency symbols like $, €, or financial terms like EBITDA, P/E ratio) → NEUTRAL (1.00)</p><p style='color:green'>•Apply lemmatization to reduce words to their base form and improve model performance → POSITIVE (1.00)</p><p style='color:gray'>Exploratory Data Analysis (EDA): \n",
              "\n",
              "•Perform EDA to gain insights into the dataset, such as identifying the most common financial entities, understanding the distribution of different types of financial data, and identifying any potential biases or imbalances in the data → NEUTRAL (1.00)</p><p style='color:gray'>•Use visualizations like word clouds, bar plots, and scatter plots to explore the data and identify patterns → NEUTRAL (1.00)</p><p style='color:gray'>Data Augmentation: •Implement data augmentation techniques to increase the size and diversity of the training dataset, such as back-translation, synonym replacement, and entity masking → NEUTRAL (0.51)</p><p style='color:gray'>•Ensure the augmented data maintains the semantic and financial context of the original data → NEUTRAL (0.99)</p><p style='color:gray'>Milestone 2: Weeks 3-4 (Financial NER Model) Model Selection: •Explore various NER models, such as Conditional Random Fields (CRF), Bi-LSTM-CRF, and transformer-based models like BERT, FinBERT, and GPT → NEUTRAL (1.00)</p><p style='color:gray'>•Evaluate the performance of each model on a validation set to select the best-performing model for further fine-tuning → NEUTRAL (1.00)</p><p style='color:gray'>Model Training: •Fine-tune the selected model on the preprocessed financial data using techniques like transfer learning and domain-specific fine-tuning → NEUTRAL (0.99)</p><p style='color:gray'>•Experiment with different hyperparameters, such as learning rate, batch size, and number of epochs, to optimize model performance → NEUTRAL (1.00)</p><p style='color:gray'>Evaluation and Error Analysis: •Evaluate the model's performance using domain-specific metrics like precision, recall, and F1-score for financial entities → NEUTRAL (1.00)</p><p style='color:red'>•Conduct error analysis to identify common mistakes and areas for improvement, such as misclassifications of complex financial terms or entities with low frequency in the training data → NEGATIVE (0.84)</p><p style='color:gray'>Model Refinement: •Refine the model based on the error analysis, such as adding more training data, adjusting hyperparameters, or incorporating additional features like financial dictionaries or knowledge bases → NEUTRAL (1.00)</p><p style='color:gray'>•Repeat the training and evaluation process until the desired performance is achieved → NEUTRAL (0.85)</p><p style='color:gray'>Milestone 3: Weeks 5-6 (Custom Financial Data Extraction) User-Defined Entity Extraction: \n",
              "•Implement a system that allows users to specify the financial entities they wish to extract, such as stock price trends, market cap, revenue growth, or earnings per share (EPS) → NEUTRAL (1.00)</p><p style='color:green'>•Develop methods to extract user-defined entities from the financial texts, leveraging the fine-tuned NER model and incorporating additional domain-specific rules or heuristics → POSITIVE (0.74)</p><p style='color:gray'>Extraction of Financial Events: •Implement a model to detect financial events, such as mergers and acquisitions, stock splits, IPO announcements, and earnings calls → NEUTRAL (1.00)</p><p style='color:gray'>•Provide users with the ability to focus on particular events within a specified timeframe → NEUTRAL (0.51)</p><p style='color:gray'>•Utilize techniques like event extraction and relation extraction to identify and extract relevant financial events from the text → NEUTRAL (1.00)</p><p style='color:gray'>Integration with Financial Databases: •Link the extracted data with financial databases (e → NEUTRAL (1.00)</p><p style='color:gray'>g → NEUTRAL (0.98)</p><p style='color:gray'>, Yahoo Finance, Bloomberg) to verify the accuracy and completeness of the extracted information → NEUTRAL (1.00)</p><p style='color:gray'>•Use the integrated data to provide additional context and insights to users, such as historical trends or industry benchmarks → NEUTRAL (1.00)</p><p style='color:gray'>Milestone 4: Weeks 7-8 (Financial Document Segmentation and Parsing) Financial Report Segmentation: •Segment financial documents (e → NEUTRAL (1.00)</p><p style='color:gray'>g → NEUTRAL (0.98)</p><p style='color:gray'>, annual reports or 10-K filings) into meaningful sections such as \"Management's Discussion and Analysis\" (MD&A), financial statements, and risk factors → NEUTRAL (1.00)</p><p style='color:gray'>•Develop methods to identify and extract relevant sections based on their content and structure, ensuring accurate extraction of financial data → NEUTRAL (0.80)</p><p style='color:gray'>Parsing of Financial Tables: •Implement methods to identify and extract financial data from structured and semi-structured tables, commonly found in financial reports → NEUTRAL (1.00)</p><p style='color:gray'>•Develop techniques to parse and extract data from tables, ensuring the proper extraction of balance sheet items, cash flow figures, and profit and loss statements → NEUTRAL (1.00)</p><p style='color:gray'>Final Model Evaluation and Deployment: •Conduct a comprehensive evaluation of the entire system, including the NER model, custom financial data extraction, and financial document segmentation and parsing → NEUTRAL (1.00)</p><p style='color:green'>•Optimize the system for performance and scalability, ensuring it can handle large volumes of financial data efficiently → POSITIVE (1.00)</p><p style='color:green'>•Deploy the system in a production environment, providing a user-friendly interface for accessing the extracted financial data and insights → POSITIVE (1.00)</p><p style='color:gray'>Evaluation Criteria  Milestone 1: Weeks 1-2 (Data Preparation) •Data Quality: Completeness and relevance of the collected financial corpus → NEUTRAL (1.00)</p><p style='color:gray'>•Exploratory Data Analysis (EDA): Insights gained from EDA, including visualizations that showcase the distribution of financial entities → NEUTRAL (0.99)</p><p style='color:green'>Milestone 2: Weeks 3-4 (Financial NER Model) •Preprocessing Effectiveness: Successful implementation of data cleaning techniques, including tokenization and lemmatization → POSITIVE (1.00)</p><p style='color:gray'>•Model Performance: Evaluation metrics such as precision, recall, and F1-score for the NER model on financial entities → NEUTRAL (1.00)</p><p style='color:gray'>Milestone 3: Weeks 5-6 (Custom Financial Data Extraction) •User Feedback: Accuracy and completeness of user-defined entity extraction based on real user inputs → NEUTRAL (1.00)</p><p style='color:green'>•Event Detection Accuracy: Effectiveness in identifying financial events like mergers and earnings calls → POSITIVE (0.96)</p><p style='color:gray'>Milestone 4: Weeks 7-8 (Financial Document Segmentation and Parsing) •Segmentation Accuracy: Precision in segmenting financial documents into relevant sections → NEUTRAL (1.00)</p><p style='color:gray'>•Data Extraction Quality: Accuracy of extracted financial data from structured tables and documents → NEUTRAL (0.96)</p><p style='color:green'>Conclusion The proposed project will develop a powerful NER-based tool to extract financial data from text sources efficiently → POSITIVE (1.00)</p><p style='color:green'>By focusing on financial entities such as company performance metrics, stock prices, earnings, and market events, this project will deliver valuable insights to financial analysts and investors → POSITIVE (1.00)</p><p style='color:gray'>The ability to customize data extraction based on user needs will make this tool adaptable for various financial applications, including risk assessment, investment research, and market analysis → NEUTRAL (0.90)</p></body></html>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 7 –  Download Output Files**"
      ],
      "metadata": {
        "id": "ufxR3CgRJ1ft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"sample_financial_report.txt\")\n",
        "files.download(\"finbert_results.html\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "BmKgwTVVEtMu",
        "outputId": "20ff4239-8127-49bc-f707-58df08e3207b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6153cd63-863c-4f82-aad9-4482b249ae2b\", \"sample_financial_report.txt\", 280)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_bbc079e0-bb6a-42dd-8308-ea1583cbbe0e\", \"finbert_results.html\", 563)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}